{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e0ffc1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import re\n",
    "from pyspark.mllib.recommendation import Rating\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import explode, col\n",
    "\n",
    "# Part A Q1\n",
    "class EvenOddCounter:\n",
    "    def __init__(self, appName, filePath):\n",
    "        try:\n",
    "            # Attempt to create a SparkSession\n",
    "            self.spark = SparkSession.builder.appName(appName).getOrCreate()\n",
    "            # If successful, store the filePath\n",
    "            self.filePath = filePath\n",
    "            print(\"SparkSession created successfully with appName:\", appName)\n",
    "        except Exception as e:\n",
    "            # If an error occurs, print the error message\n",
    "            print(\"Failed to create SparkSession:\", e)\n",
    "        \n",
    "    #function for counting even and odd numbers in the file\n",
    "    def countEvenOdd(self):\n",
    "        # Load the text file into an RDD\n",
    "        numbers_rdd = self.spark.sparkContext.textFile(self.filePath)\n",
    "\n",
    "        # Define transformations to filter even and odd numbers\n",
    "        even_numbers = numbers_rdd.flatMap(lambda line: line.split(\" \"))\\\n",
    "                                  .filter(lambda word: word.isdigit())\\\n",
    "                                  .map(lambda number: int(number))\\\n",
    "                                  .filter(lambda number: number % 2 == 0)\n",
    "        odd_numbers = numbers_rdd.flatMap(lambda line: line.split(\" \"))\\\n",
    "                                 .filter(lambda word: word.isdigit())\\\n",
    "                                 .map(lambda number: int(number))\\\n",
    "                                 .filter(lambda number: number % 2 != 0)\n",
    "\n",
    "        # Count even and odd numbers\n",
    "        even_count = even_numbers.count()\n",
    "        odd_count = odd_numbers.count()\n",
    "\n",
    "        # Return the counts\n",
    "        return even_count, odd_count\n",
    "    \n",
    "    #method to save counts to a txt file\n",
    "    def saveCountsToFile(self, evenCount, oddCount, outputPath):\n",
    "        # Save the counts to a specified text file\n",
    "        with open(outputPath, 'w') as file:\n",
    "            file.write(f\"Even numbers count: {evenCount}\\n\")\n",
    "            file.write(f\"Odd numbers count: {oddCount}\\n\")\n",
    "        print(f\"Counts saved to {outputPath}\")\n",
    "\n",
    "    def stop(self):\n",
    "        self.spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf1077c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession created successfully with appName: EvenOddCounter\n",
      "Even Counts: 514 \n",
      "Odd Counts 496\n",
      "Counts saved to /Users/declanbracken/Development/UofT_Projects/MIE_1628/A2/output_files/Even_Odd_counts.tex\n"
     ]
    }
   ],
   "source": [
    "filepath = \"/Users/declanbracken/Development/UofT_Projects/MIE_1628/A2/integer.txt\"\n",
    "counter = EvenOddCounter(\"EvenOddCounter\",filepath)\n",
    "outputpath = \"/Users/declanbracken/Development/UofT_Projects/MIE_1628/A2/output_files/Even_Odd_counts.tex\"\n",
    "even_count, odd_count = counter.countEvenOdd()\n",
    "print(f\"Even Counts: {even_count} \\nOdd Counts: {odd_count}\")\n",
    "counter.saveCountsToFile(even_count, odd_count, outputpath)\n",
    "counter.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4540a7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part A Q2\n",
    "class DepartmentSalarySum:\n",
    "    def __init__(self, appName, filePath):\n",
    "        self.spark = SparkSession.builder.appName(appName).getOrCreate()\n",
    "        self.filePath = filePath\n",
    "\n",
    "    def calculateSalarySums(self):\n",
    "        # Load the text file into an RDD\n",
    "        lines_rdd = self.spark.sparkContext.textFile(self.filePath)\n",
    "\n",
    "        # Map each line to a (department, salary) pair\n",
    "        department_salary_rdd = lines_rdd.map(lambda line: line.split(\" \"))\\\n",
    "                                          .map(lambda parts: (parts[0], float(parts[1])))\n",
    "\n",
    "        # Reduce by key (department) to sum the salaries\n",
    "        department_sums_rdd = department_salary_rdd.reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "        # Collect the results as a list of tuples\n",
    "        department_sums = department_sums_rdd.collect()\n",
    "\n",
    "        return department_sums\n",
    "\n",
    "    def saveDepartmentSumsToFile(self, departmentSums, outputPath):\n",
    "        # Save the department sums to a specified text file\n",
    "        with open(outputPath, 'w') as file:\n",
    "            for department, sum in departmentSums:\n",
    "                file.write(f\"{department}: {sum}\\n\")\n",
    "        print(f\"Department salary sums saved to {outputPath}\")\n",
    "\n",
    "    def stop(self):\n",
    "        self.spark.stop()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee954620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Departments and sums:\n",
      "[('Sales', 3488491.0), ('Research', 3328284.0), ('Developer', 3221394.0), ('QA', 3360624.0), ('Marketing', 3158450.0)]\n",
      "Department salary sums saved to /Users/declanbracken/Development/UofT_Projects/MIE_1628/A2/output_files/department_sums.tex\n"
     ]
    }
   ],
   "source": [
    "filepath2 = \"/Users/declanbracken/Development/UofT_Projects/MIE_1628/A2/salary.txt\"\n",
    "outputpath2 = \"/Users/declanbracken/Development/UofT_Projects/MIE_1628/A2/output_files/department_sums.tex\"\n",
    "salarycounter = DepartmentSalarySum(\"SalarySum\",filepath2)\n",
    "departmentsums = salarycounter.calculateSalarySums()\n",
    "print(f\"Departments and sums:\\n{departmentsums}\")\n",
    "salarycounter.saveDepartmentSumsToFile(departmentsums,outputpath2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fafb3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part A Q3\n",
    "class WordCount:\n",
    "    def __init__(self, appName, filePath):\n",
    "        self.spark = SparkSession.builder.appName(appName).getOrCreate()\n",
    "        self.filePath = filePath\n",
    "\n",
    "    def CountWords(self, keyword_list):\n",
    "        # Load the text file into an RDD\n",
    "        lines_rdd = self.spark.sparkContext.textFile(self.filePath)\n",
    "        \n",
    "        # Split lines into words, also SPLIT PUNCTUATION so that words adjacent to punctuation are still counted!!\n",
    "        # IE: 'WILLIAM.' will be counted even though 'WILLIAM' != 'WILLIAM.'\n",
    "        words = lines_rdd.flatMap(lambda line: re.split(r'\\W+', line))\n",
    "        \n",
    "        # Filter only words in keyword list\n",
    "        keyword_pairs = words.filter(lambda word: word in keyword_list).map(lambda word: (word, 1))\n",
    "        \n",
    "        # Reduce (count) pairs\n",
    "        keyword_counts = keyword_pairs.reduceByKey(lambda a, b: a + b)\n",
    "        \n",
    "        # Collect keyword and counts back to the driver program\n",
    "        collected_pairs = keyword_counts.collect()\n",
    "        \n",
    "        return collected_pairs\n",
    "\n",
    "        \n",
    "    def saveWordCount(self, collected_pairs, outputPath):\n",
    "        # Save the keyword counts to a txt file\n",
    "        with open(outputPath, 'w') as file:\n",
    "            for keyword, count in collected_pairs:\n",
    "                file.write(f\"{keyword}: {count}\\n\")\n",
    "        print(f\"Keyword counts saved to {outputPath}\")\n",
    "\n",
    "    def stop(self):\n",
    "        self.spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15be7797",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/25 12:58:11 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words and their counts:\n",
      "[('Shakespeare', 22), ('WILLIAM', 128), ('COLLEGE', 98), ('When', 406), ('GUTENBERG', 100), ('Library', 5), ('WORLD', 98), ('Lord', 402)]\n",
      "Keyword counts saved to /Users/declanbracken/Development/UofT_Projects/MIE_1628/A2/output_files/shakespeare_wordcounts.tex\n"
     ]
    }
   ],
   "source": [
    "filepath3 = \"/Users/declanbracken/Development/UofT_Projects/MIE_1628/A2/shakespeare-2.txt\" #input path\n",
    "keywords = [\"Shakespeare\", \"When\", \"Lord\", \"Library\", \"GUTENBERG\", \"WILLIAM\", \"COLLEGE\", \"WORLD\"] #Keyword list\n",
    "outputpath3 = \"/Users/declanbracken/Development/UofT_Projects/MIE_1628/A2/output_files/shakespeare_wordcounts.tex\" #output path\n",
    "\n",
    "word_counter = WordCount(\"WordCounter\",filepath3)\n",
    "collected_pairs = word_counter.CountWords(keywords)\n",
    "print(f\"Words and their counts:\\n{collected_pairs}\")\n",
    "word_counter.saveWordCount(collected_pairs, outputpath3)\n",
    "word_counter.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09c85092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part A Q4\n",
    "\n",
    "class WordCount2:\n",
    "    def __init__(self, appName, filePath):\n",
    "        self.spark = SparkSession.builder.appName(appName).getOrCreate()\n",
    "        self.filePath = filePath\n",
    "\n",
    "    def CountWords(self, keyword_list):\n",
    "        # Load the text file into an RDD\n",
    "        lines_rdd = self.spark.sparkContext.textFile(self.filePath)\n",
    "        \n",
    "        # Split lines into words, also SPLIT PUNCTUATION so that words adjacent to punctuation are still counted!!\n",
    "        # IE: 'WILLIAM.' will be counted even though 'WILLIAM' != 'WILLIAM.'\n",
    "        words = lines_rdd.flatMap(lambda line: re.split(r'\\W+', line.lower())).filter(lambda word: word != \"\") # make lowercase for case insensitivity\n",
    "        \n",
    "        # map words to single value\n",
    "        keyword_pairs = words.map(lambda word: (word, 1))\n",
    "        \n",
    "        # Reduce (count) pairs\n",
    "        keyword_counts = keyword_pairs.reduceByKey(lambda a, b: a + b)\n",
    "        \n",
    "        # Sort the counts in ascending order (for bottom 15) and then in descending order (for top 15)\n",
    "        sorted_counts_asc = keyword_counts.sortBy(lambda pair: pair[1])\n",
    "        sorted_counts_desc = keyword_counts.sortBy(lambda pair: pair[1], ascending=False)\n",
    "\n",
    "        # Take the top 15 and bottom 15 entries\n",
    "        top_15 = sorted_counts_desc.take(15)\n",
    "        bottom_15 = sorted_counts_asc.take(15)\n",
    "        \n",
    "        # Print\n",
    "        print(\"Top 15 words by count (case insensitive): \\n\", top_15)\n",
    "        print(\"\\n\\nBottom 15 words by count (case insensitive): \\n\", bottom_15)\n",
    "        \n",
    "        return top_15, bottom_15\n",
    "\n",
    "        \n",
    "    def saveWordCount(self, top_15, bot_15, outputPath):\n",
    "        # Save the keyword counts to a txt file\n",
    "        with open(outputPath, 'w') as file:\n",
    "            file.write(\"Top 15 words:\\n\")\n",
    "            for keyword, count in top_15:\n",
    "                file.write(f\"{keyword}: {count}\\n\")\n",
    "            file.write(\"Bottom 15 words:\\n\")\n",
    "            for keyword, count in bottom_15:\n",
    "                file.write(f\"{keyword}: {count}\\n\")\n",
    "            \n",
    "        print(f\"Keyword counts saved to {outputPath}\")\n",
    "\n",
    "    def stop(self):\n",
    "        self.spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4afa43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 words by count (case insensitive): \n",
      " [('the', 13717), ('and', 12974), ('i', 9874), ('of', 9382), ('to', 9351), ('a', 6725), ('you', 6154), ('my', 5699), ('that', 5409), ('in', 5341), ('d', 4369), ('is', 4344), ('not', 3917), ('for', 3887), ('with', 3817)]\n",
      "\n",
      "\n",
      "Bottom 15 words by count (case insensitive): \n",
      " [('restrictions', 1), ('online', 1), ('www', 1), ('org', 1), ('2011', 1), ('release', 1), ('january', 1), ('cdroms', 1), ('releases', 1), ('implications', 1), ('materials', 1), ('provisions', 1), ('proprietary', 1), ('underline', 1), ('punctuation', 1)]\n",
      "Keyword counts saved to /Users/declanbracken/Development/UofT_Projects/MIE_1628/A2/output_files/top15_bottom15.tex\n"
     ]
    }
   ],
   "source": [
    "filepath4 = \"/Users/declanbracken/Development/UofT_Projects/MIE_1628/A2/shakespeare-2.txt\" #input path\n",
    "outputpath4 = \"/Users/declanbracken/Development/UofT_Projects/MIE_1628/A2/output_files/top15_bottom15.tex\" #output path\n",
    "\n",
    "word_counter2 = WordCount2(\"WordCounter2\",filepath4)\n",
    "top_15, bottom_15 = word_counter2.CountWords(keywords)\n",
    "word_counter2.saveWordCount(top_15, bottom_15, outputpath4)\n",
    "word_counter2.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "99275842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part B\n",
    "\"\"\" Note:\n",
    "This is where I stopped creating output txt files since i figured there was no point, and that I can just use the\n",
    "outputs from within this notebook, aswell as copy and paste them into my pdf document. In the future I will use\n",
    "databricks, but I didn't get the memo this time, so I hope this notebook will suffice.\n",
    "\"\"\"\n",
    "\n",
    "class CreateMovieRecommender:\n",
    "    def __init__(self, appName, filePath):\n",
    "        self.spark = SparkSession.builder.appName(appName).getOrCreate()\n",
    "        self.filePath = filePath\n",
    "        \n",
    "    def LoadData(self):\n",
    "        # Load the CSV file into an RDD\n",
    "        movie_data = self.spark.sparkContext.textFile(self.filePath)\n",
    "\n",
    "        # Index each row and filter out the first row (header)\n",
    "        header = movie_data.first()\n",
    "        self.movie_data_parsed = movie_data.filter(lambda line: line != header).map(lambda line: line.split(\",\"))\n",
    "    \n",
    "    # Part 1\n",
    "    def GetHighestRatedMovie(self):\n",
    "        # Map to (movieId, (rating, 1)) for summing and counting\n",
    "        movie_ratings = self.movie_data_parsed.map(lambda tokens: (tokens[0], (float(tokens[1]), 1)))\n",
    "        # Reduce by key to sum ratings and count\n",
    "        movie_rating_totals = movie_ratings.reduceByKey(lambda a, b: (a[0] + b[0], a[1] + b[1]))\n",
    "        # Calculate average ratings\n",
    "        movie_average_ratings = movie_rating_totals.mapValues(lambda total_count: total_count[0] / total_count[1])\n",
    "        # Sort by average rating\n",
    "        sorted_movies = movie_average_ratings.sortBy(lambda movie_rating: movie_rating[1], ascending=False)\n",
    "        # Take the top movie\n",
    "        highest_rated_movie = sorted_movies.first()\n",
    "        return highest_rated_movie\n",
    "\n",
    "    def GetUserWithHighestRatings(self):\n",
    "        # Map to (userId, rating) for summing\n",
    "        user_ratings = self.movie_data_parsed.map(lambda tokens: (tokens[2], float(tokens[1])))\n",
    "        # Reduce by key to sum ratings\n",
    "        user_rating_totals = user_ratings.reduceByKey(lambda a, b: a + b)\n",
    "        # Sort by total rating\n",
    "        sorted_users = user_rating_totals.sortBy(lambda user_rating: user_rating[1], ascending=False)\n",
    "        # Take the top user\n",
    "        highest_rating_user = sorted_users.first()\n",
    "        return highest_rating_user\n",
    "    \n",
    "    # Part 2: Create a train-test split and then return a trained model (This class creates models, but they're stored externally.)\n",
    "    def TrainModel(self, numIterations = 10, rank = 10, regParam = 0.01, testSplit = 0.2):\n",
    "        \n",
    "        # Create dataset as rating object from mllib library\n",
    "        self.movie_data_ratings  = self.movie_data_parsed.map(lambda p: Row(userId=int(p[2]), movieId=int(p[0]),\n",
    "                                         rating=float(p[1])))\n",
    "        \n",
    "        # Split data into train and test\n",
    "        self.ratings = self.spark.createDataFrame(self.movie_data_ratings) #create ratings as spark dataframe\n",
    "        (train_data, test_data) = self.ratings.randomSplit([1 - testSplit, testSplit], seed = 0) # use 0 seed\n",
    "        \n",
    "        # Create ALS Object\n",
    "        als = ALS(maxIter=numIterations, rank = rank, regParam = regParam, userCol=\"userId\", \n",
    "                  itemCol=\"movieId\", ratingCol=\"rating\", coldStartStrategy=\"drop\", seed = 0) # use 0 seed\n",
    "        \n",
    "        model = als.fit(train_data) #Train\n",
    "        \n",
    "        return model, test_data\n",
    "    \n",
    "    # Part 3\n",
    "    def EvaluateModel(self, model, test_data):\n",
    "\n",
    "        # Evaluate the model by getting predictions\n",
    "        predictions = model.transform(test_data)\n",
    "        \n",
    "        # calculate RMSE\n",
    "        rmse_evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                                        predictionCol=\"prediction\")\n",
    "        rmse = rmse_evaluator.evaluate(predictions)\n",
    "        print(\"Root-mean-square error = \" + str(rmse))\n",
    "        \n",
    "        # calculate MAE\n",
    "        mae_evaluator = RegressionEvaluator(metricName=\"mae\", labelCol=\"rating\",\n",
    "                                        predictionCol=\"prediction\")\n",
    "        mae = mae_evaluator.evaluate(predictions)\n",
    "        print(\"Mean-absolute error = \" + str(mae))\n",
    "        \n",
    "        return rmse, mae\n",
    "    \n",
    "    # Part 5\n",
    "    def RecommendMovies(self, model, user_id, num_recommendations):\n",
    "        # Recommend movies for the user\n",
    "        \n",
    "        # Generate top movie recommendations for specific user\n",
    "        user = self.ratings.filter(self.ratings.userId == user_id) # Get user reviews\n",
    "        userSubsetRecs = model.recommendForUserSubset(user, num_recommendations) # Get Recommendations\n",
    "\n",
    "        print(f\"Top {num_recommendations} for user {user_id}:\") # Print:\n",
    "        \n",
    "        # Explode the recommendations to flatten the DataFrame\n",
    "        recommendations = userSubsetRecs \\\n",
    "            .withColumn(\"recommendation\", explode(\"recommendations\")) \\\n",
    "            .select(\n",
    "                col(\"userId\"),\n",
    "                col(\"recommendation.*\")\n",
    "            )\n",
    "\n",
    "        # Show the recommendations\n",
    "        recommendations.show()\n",
    "        \n",
    "        # Return the recommended movie IDs\n",
    "        return userSubsetRecs\n",
    "    \n",
    "    def stop(self):\n",
    "        self.spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6007fc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest rated movie ID: 32, with average rating: 2.9166666666666665\n",
      "User ID with highest rating: 11, total rating: 128.0\n",
      "\n",
      "80-20 split performance:\n",
      "\n",
      "Root-mean-square error = 1.852018322300239\n",
      "Mean-absolute error = 1.355651779338769\n",
      "\n",
      "70-30 split performance:\n",
      "\n",
      "Root-mean-square error = 2.469070292648919\n",
      "Mean-absolute error = 1.821911167812746\n"
     ]
    }
   ],
   "source": [
    "filepath5 = \"/Users/declanbracken/Development/UofT_Projects/MIE_1628/A2/movies.csv\" #input path\n",
    "\n",
    "# Create movie recommendation building object\n",
    "movie_recommender = CreateMovieRecommender(\"MovieRecommender\",filepath5)\n",
    "\n",
    "# Load the data\n",
    "movie_recommender.LoadData()\n",
    "\n",
    "# Part 1:\n",
    "# Get the highest rated movies\n",
    "highest_rated_movie = movie_recommender.GetHighestRatedMovie()\n",
    "print(f\"Highest rated movie ID: {highest_rated_movie[0]}, with average rating: {highest_rated_movie[1]}\")\n",
    "\n",
    "# Get the highest rated user\n",
    "highest_rated_user = movie_recommender.GetUserWithHighestRatings()\n",
    "print(f\"User ID with highest rating: {highest_rated_user[0]}, total rating: {highest_rated_user[1]}\")\n",
    "\n",
    "\n",
    "# Part 2:\n",
    "# Given the same model hyper-parameters, try 2 train-test splits:\n",
    "# Train the model on an 80-20 train-test split\n",
    "model8020, test_data_8020 = movie_recommender.TrainModel(rank = 10, numIterations = 10, testSplit = 0.2)\n",
    "print(\"\\n80-20 split performance:\\n\")\n",
    "RMSE_8020, MAE_8020 = movie_recommender.EvaluateModel(model8020, test_data_8020)\n",
    "\n",
    "# Train the model on a 70-30 train-test split\n",
    "model7030, test_data_7030 = movie_recommender.TrainModel(rank = 10, numIterations = 10, testSplit = 0.3)\n",
    "print(\"\\n70-30 split performance:\\n\")\n",
    "RMSE_7030, MAE_7030 = movie_recommender.EvaluateModel(model7030, test_data_7030)\n",
    "\n",
    "# Stop\n",
    "movie_recommender.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c3406e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "\n",
    "Part 3:\n",
    "\n",
    "MSE: \n",
    "Mean squared error is calculated as the average of the squared errors between the prediction \n",
    "and the target in a dataset: let x = prediction, x' = target value, and n = number of samples. \n",
    "    MSE = sum((x - x')^2)/n\n",
    "\n",
    "RMSE:\n",
    "Root mean squared error is nearly the same as the mean squarred error, but with an additional \n",
    "square root operation applied after averaging in order to proportionalize the RMSE to the difference\n",
    "in values between the prediction and target.\n",
    "    RMSE = sqrt(MSE)\n",
    "\n",
    "MAE:\n",
    "Mean absolute error is the average of the absolute difference in prediction and target values. \n",
    "The absolute error is different from squared error since it scales linearly with the difference\n",
    "in value between target and prediction, and is also non-differentiable around 0.\n",
    "    MAE = sum(abs(x - x'))/n\n",
    "\n",
    "RMSE is more widely used than MAE. Both are invariant to the direction of error (ranging from 0 to infinity),\n",
    "the key difference in how these loss functions behave is in how they treat outliers, and punish predictions\n",
    "which are VERY wrong. When using rmse, if a prediction is very far from the target, the error will be \n",
    "greater than a linearly proportional increase when compared to mean absolute error, in which the error will always\n",
    "scale linearly. To summarize: RMSE increases more for values which are very wrong (often outliers or bad predictions),\n",
    "while MAE is linear and treats all variance between predictions and targets the same. For me, I'd like to be\n",
    "risk adverse and implement RMSE, because I want my model to be robust and never given a completely wrong prediction\n",
    "(if possible).\n",
    "\n",
    "Part 4:\n",
    "\n",
    "To tune my collaborative filtering algorithm, I've varied the train-test split, the number of iterations, \n",
    "the matrix rank, and the regularization parameter. In varrying these parameters, I attempted to minimize\n",
    "the test data error using RMSE over MAE, as explained in the prior section.\n",
    "The other tuned hyperparameters can be explained as follows:\n",
    "\n",
    "Train-test split (not really a hyper param but i'll explain my choice anyways):\n",
    "    The ratio of data used for training vs evaluation. Given that this dataset is small, you want as much data as\n",
    "    possible to create the model, but you also don't want to skew your evaluation results by reducing the test data\n",
    "    too much. I'm opting to use slightly more training data with an 80-20 ratio, as I don't want my model to overfit\n",
    "    and feel as though in the real worlds, I can always collect more.\n",
    "\n",
    "Number of iterations:\n",
    "    the alternating least squares (ALS) method for collaborative filtering relies on an iterative approach in which\n",
    "    a latent space is produced through U-V matrix decomposition. The matrices U and V are updated cyclically, where U\n",
    "    is held constant and V is updated, then vice versa, with the goal of minimizing the least squares error for the\n",
    "    original user/item matrix and the product of the U - V matrix: min( ||R − U × V||^2 ). Therefore the number of\n",
    "    iterations are the iterations set to allow U and V to keep updating. This value needs to be balanced to avoid \n",
    "    overfitting, and over training.\n",
    "\n",
    "Rank:\n",
    "    refering back to the explanation of the ALS algorithm and U - V matrix decomposition above, the rank is the \n",
    "    dimensionality of the latent space shared between matrices U and V. Rank can be thought of almost like the size\n",
    "    of the embedding space, a rank allows the algorithm to capture greater data complexity, but also makes it more\n",
    "    likely to overfit. Alternatively, a low-rank means that not all the complexity of the data may be captured, and\n",
    "    could result in underfitting. rank and the number of iterations for the ALS algorithm should be tuned in tandem.\n",
    "\n",
    "Regularization:\n",
    "    The regularization parameter \"regParam\" is a regularization factor which effectively punishes very large values/\n",
    "    weights in the model. This is used to combat overfitting, but too high a value may similarily lead to underfitting.\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cd816a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tuned Model performance:\n",
      "\n",
      "Root-mean-square error = 0.8605250315889759\n",
      "Mean-absolute error = 0.6136316180126065\n",
      "Top 12 for user 1:\n",
      "+------+-------+---------+\n",
      "|userId|movieId|   rating|\n",
      "+------+-------+---------+\n",
      "|     1|     62|3.3536956|\n",
      "|     1|     68|3.2473934|\n",
      "|     1|     77|2.7373428|\n",
      "|     1|     22|2.3228655|\n",
      "|     1|     21|2.1096992|\n",
      "|     1|     41|2.0874867|\n",
      "|     1|     52|2.0024612|\n",
      "|     1|     94|1.9991494|\n",
      "|     1|     88|1.9760745|\n",
      "|     1|     74|1.9546779|\n",
      "|     1|     70|1.9544704|\n",
      "|     1|     30|1.8418361|\n",
      "+------+-------+---------+\n",
      "\n",
      "Top 12 for user 12:\n",
      "+------+-------+---------+\n",
      "|userId|movieId|   rating|\n",
      "+------+-------+---------+\n",
      "|    12|     46|4.5404897|\n",
      "|    12|     64|4.3234367|\n",
      "|    12|     27|4.2886424|\n",
      "|    12|     35|4.1497645|\n",
      "|    12|     55|3.8154309|\n",
      "|    12|     50|3.6875954|\n",
      "|    12|     48|3.6543837|\n",
      "|    12|     16|3.6436348|\n",
      "|    12|     94|3.5683517|\n",
      "|    12|     65| 3.462337|\n",
      "|    12|     90|3.3048935|\n",
      "|    12|     23|3.2955499|\n",
      "+------+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Part 4: Tuning\n",
    "\n",
    "\"\"\" Changes made based on only RMSE results using an 80-20 split from evaluation.\n",
    "\n",
    "Tuning changes:\n",
    "    - Regularization Parameter increased from 0.01 to 0.08\n",
    "    - Increased numIterations from 10 to 20\n",
    "    - Increased rank from 10 to 15\n",
    "\n",
    "Result:\n",
    "    RMSE decreased from 1.852 to 0.860 !\n",
    "\"\"\"\n",
    "\n",
    "# Create movie recommendation building object\n",
    "movie_recommender = CreateMovieRecommender(\"MovieRecommender\",filepath5)\n",
    "\n",
    "# Load the data\n",
    "movie_recommender.LoadData()\n",
    "\n",
    "# Train the model on an 80-20 train-test split\n",
    "model, test_data = movie_recommender.TrainModel(rank = 15, numIterations = 20, regParam = 0.08, testSplit = 0.2)\n",
    "print(\"\\nTuned Model performance:\\n\")\n",
    "RMSE, MAE = movie_recommender.EvaluateModel(model, test_data)\n",
    "\n",
    "# Part 5:\n",
    "\n",
    "# Recommendations for user 1:\n",
    "recommendations_user1 = movie_recommender.RecommendMovies(model, 1, 12)\n",
    "\n",
    "recommendations_user12 = movie_recommender.RecommendMovies(model, 12, 12)\n",
    "\n",
    "movie_recommender.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
